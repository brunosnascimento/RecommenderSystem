{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import joblib\n",
    "import os.path\n",
    "from messaging.telegrambot import Bot\n",
    "import telegram\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam # PODE MUDAR\n",
    "import keras.callbacks as callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loading Time: 0.158306121826 s] rating.csv Shape:  (100000, 4)\n"
     ]
    }
   ],
   "source": [
    "#Loading dataset\n",
    "\n",
    "dataset = '100k/' #100k dataset path\n",
    "#dataset = '10M/' #10M dataset path\n",
    "#dataset = '20M/' #20M dataset path\n",
    "\n",
    "dataset_path = '../../Datasets/movieLens/' + dataset; # Full dataset path\n",
    "\n",
    "filenames = {'movie': 'movie.csv', 'rating': 'rating.csv'};\n",
    "\n",
    "time_zero = time.time();\n",
    "#df_movies = pd.read_csv(dataset_path+filenames['movie'], error_bad_lines=False);\n",
    "#print \"[Loading Time:\",time.time()-time_zero,\"s]\",filenames['movie'],'Shape: ', df_movies.shape;\n",
    "\n",
    "#print df_movies.head();\n",
    "#print df_movies.tail();\n",
    "\n",
    "global df_ratings;\n",
    "df_ratings = pd.read_csv(dataset_path+filenames['rating']);\n",
    "print \"[Loading Time:\",time.time()-time_zero,\"s]\",filenames['rating'],'Shape: ', df_ratings.shape;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      "userId       100000 non-null int64\n",
      "movieId      100000 non-null int64\n",
      "rating       100000 non-null int64\n",
      "timestamp    100000 non-null int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 3.1 MB\n",
      "None\n",
      "   userId  movieId  rating  timestamp\n",
      "0     196      242       3  881250949\n",
      "1     186      302       3  891717742\n",
      "2      22      377       1  878887116\n",
      "3     244       51       2  880606923\n",
      "4     166      346       1  886397596\n",
      "       userId  movieId  rating  timestamp\n",
      "99995     880      476       3  880175444\n",
      "99996     716      204       5  879795543\n",
      "99997     276     1090       1  874795795\n",
      "99998      13      225       2  882399156\n",
      "99999      12      203       3  879959583\n"
     ]
    }
   ],
   "source": [
    "print df_ratings.info();\n",
    "print df_ratings.head();\n",
    "print df_ratings.tail();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global usersIds;\n",
    "global moviesIds;\n",
    "\n",
    "def InitializeIds():\n",
    "    global usersIds;\n",
    "    global moviesIds;\n",
    "\n",
    "\n",
    "    usersIds = np.zeros(1);\n",
    "    moviesIds = np.zeros(1);\n",
    "\n",
    "\n",
    "    for count in xrange(len(df_ratings['rating'])):\n",
    "\n",
    "        if df_ratings['userId'][count] in usersIds:\n",
    "            pass;\n",
    "        else:\n",
    "            usersIds = np.append(usersIds, df_ratings['userId'][count]);   \n",
    "\n",
    "        if df_ratings['movieId'][count] in moviesIds:\n",
    "            pass;\n",
    "        else:\n",
    "            moviesIds = np.append(moviesIds, df_ratings['movieId'][count]);\n",
    "            currentMovieId = df_ratings['movieId'][count];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Ids array:\t(944,)\n",
      "Movies Ids array:\t(1683,)\n",
      "Elapsed time:  2.98928284645\n"
     ]
    }
   ],
   "source": [
    "#Counting Number of Unique Users and Movies\n",
    "time_zero = time.time();\n",
    "\n",
    "InitializeIds();            \n",
    "            \n",
    "print \"Users Ids array:\\t\",usersIds.shape\n",
    "print \"Movies Ids array:\\t\", moviesIds.shape;\n",
    "print \"Elapsed time: \", time.time()-time_zero; # Aprox. 370 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility Matrix shape:  (944, 1683)\n",
      "Utility Matrix Memory Usage:  12710.128\n",
      "[*] Saving original utility variable...\n",
      "[*] Saving variable to ./Results/Variables/100k/originalUtilityMatrix file...\n",
      "[*] Removing existing file...\n",
      "[+] Existing file removed.\n",
      "[+] File saved.\n",
      "[+] Variable saved.\n",
      "Elapsed time:  7.12597799301\n"
     ]
    }
   ],
   "source": [
    "# Auxiliary Functions\n",
    "global R;\n",
    "global results_path;\n",
    "results_path = './Results/';\n",
    "\n",
    "def InitializeUtilityMatrix():\n",
    "    InitializeIds();\n",
    "    return np.zeros((usersIds.shape[0], moviesIds.shape[0]));\n",
    "\n",
    "def FillUtilityMatrix():\n",
    "    global R;\n",
    "    for register in xrange(len(df_ratings['userId'])):\n",
    "        userId = df_ratings['userId'][register];\n",
    "        movieId = df_ratings['movieId'][register];\n",
    "\n",
    "        #Getting userIndex from usersIds\n",
    "        #itemindex = numpy.where(array==item) --> Return an array with indexes found\n",
    "        userIndex = np.where(usersIds == userId);\n",
    "        if len(userIndex[0]) == 0: # If userIndex hasn't found any matching user id in usersIds array\n",
    "            print \"UserId\", userId, \"not found in usersIds array.\";\n",
    "            pass;\n",
    "        else:\n",
    "            try:\n",
    "                if len(userIndex[0]) > 1:\n",
    "                    print \"UserId \", userId, \"is double-counted in usersIds.\";\n",
    "                userIndex = userIndex[0][0]; #Get the first occurance of userId match\n",
    "            except IndexError:\n",
    "                print \"Error with user index: \", userIndex[0] ;\n",
    "                pass;\n",
    "\n",
    "\n",
    "        #Getting movieIndex from moviesIds\n",
    "        #itemindex = numpy.where(array==item) --> Return an array with indexes found\n",
    "        movieIndex = np.where(moviesIds == movieId);\n",
    "        if len(movieIndex[0]) == 0: # If userIndex hasn't found any matching user id in usersIds array\n",
    "            print \"MovieId\", movieId, \"not found in usersIds array.\";\n",
    "            pass;\n",
    "        else:\n",
    "            try:\n",
    "                if len(movieIndex[0]) > 1:\n",
    "                    print \"MovieId \", movieId, \"is double-counted in moviesIds.\";\n",
    "                movieIndex = movieIndex[0][0]; #Get the first occurance of movieId match\n",
    "            except IndexError:\n",
    "                print \"Error with movie index: \", movieIndex[0] ;\n",
    "                pass;            \n",
    "\n",
    "        R[userIndex][movieIndex] = df_ratings['rating'][register];\n",
    "        \n",
    "    return R;\n",
    "\n",
    "def saveVariable(filename, variable):\n",
    "    \n",
    "    compression_parameter = 9;\n",
    "    \n",
    "    filepath = results_path+\"Variables/\"+dataset+filename;\n",
    "    print \"[*] Saving variable to \" + filepath + \" file...\";\n",
    "    if os.path.isfile(filepath): #Check if file already exists\n",
    "        print \"[*] Removing existing file...\";\n",
    "        os.remove(filepath);\n",
    "        print \"[+] Existing file removed.\";    \n",
    "\n",
    "    #joblib.dump(value, filename, compress=0, protocol=None, cache_size=None)\n",
    "    joblib.dump(variable, filepath, compress = compression_parameter);\n",
    "    print \"[+] File saved.\";   \n",
    "import sys\n",
    "\n",
    "time_zero = time.time();\n",
    "\n",
    "R = InitializeUtilityMatrix();\n",
    "R = FillUtilityMatrix();\n",
    "\n",
    "print \"Utility Matrix shape: \", R.shape;\n",
    "\n",
    "KILO = 1000.0\n",
    "MEGA = 1000*KILO;\n",
    "GIGA = 1000*MEGA\n",
    "print \"Utility Matrix Memory Usage: \", sys.getsizeof(R)/(KILO)\n",
    "\n",
    "#Saving variable\n",
    "filename = 'originalUtilityMatrix';\n",
    "print \"[*] Saving original utility variable...\"\n",
    "saveVariable(filename, R); # saveVariable(filename, variable):\n",
    "print \"[+] Variable saved.\"\n",
    "\n",
    "\n",
    "print \"Elapsed time: \", time.time() - time_zero;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(944, 1683)\n",
      "(708, 1683)\n",
      "(236, 1683)\n"
     ]
    }
   ],
   "source": [
    "print R.shape\n",
    "#entrada_treinamento = R[:600,:]\n",
    "#entrada_validacao = R[600:,:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "entrada_treinamento, entrada_validacao = train_test_split(R)\n",
    "\n",
    "print entrada_treinamento.shape\n",
    "print entrada_validacao.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                26944     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1683)              28611     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1683)              0         \n",
      "=================================================================\n",
      "Total params: 55,827\n",
      "Trainable params: 55,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "num_neurons = 16\n",
    "\n",
    "# Usuario - Linha = Register\n",
    "# Filme - COlunea = Feature\n",
    "\n",
    "# Camada 0 -> Entrada \n",
    "# Camada 1 -> Hidden (SELU)\n",
    "# Camada 2 -> Dropout\n",
    "# Camada 3 -> Hidden (SELU)\n",
    "# Camada 4 -> Saida (tngh)\n",
    "\n",
    "# Entrada --> Hidden(Wk) --> Dropout --> Hidden(WkT) --> Entrada'\n",
    "\n",
    "# Inicializando \n",
    "model = Sequential()\n",
    "\n",
    "# Encoder\n",
    "model.add(Dense(units=num_neurons, input_dim=R.shape[1], kernel_initializer='uniform', trainable = True))\n",
    "# Trainable serve para eu treinar só uma camada. Posso fazer treinamento layer wise com isso\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "# Camada de dropout\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Dense(units=num_neurons, kernel_initializer='uniform'))\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "# Decoder\n",
    "model.add(Dense(units=R.shape[1], kernel_initializer='uniform'))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "#1683 --> Encoder(tanh) --> 10 --> Decoder --> 1683\n",
    "# 1683 --> 1ª  Encoder Camada(750) --> 2ª Camada ... -> classificador (n neuronios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                        patience=10,\n",
    "                                        mode='auto')\n",
    "\n",
    "trn_desc = model.fit(entrada_treinamento, entrada_treinamento,\n",
    "                    epochs=100,\n",
    "                    batch_size=1,\n",
    "                    callbacks=[earlyStopping],\n",
    "                    verbose=True,\n",
    "                    validation_data=(entrada_validacao,entrada_validacao))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0042372881355932203,\n",
       " 0.0084745762711864406,\n",
       " 0.0084745762711864406,\n",
       " 0.012711864406779662,\n",
       " 0.021186440677966101,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.0084745762711864406,\n",
       " 0.021186440677966101,\n",
       " 0.021186440677966101,\n",
       " 0.021186440677966101,\n",
       " 0.016949152542372881,\n",
       " 0.016949152542372881,\n",
       " 0.016949152542372881,\n",
       " 0.021186440677966101,\n",
       " 0.012711864406779662,\n",
       " 0.016949152542372881,\n",
       " 0.016949152542372881,\n",
       " 0.012711864406779662,\n",
       " 0.016949152542372881,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.016949152542372881,\n",
       " 0.016949152542372881,\n",
       " 0.016949152542372881,\n",
       " 0.016949152542372881,\n",
       " 0.016949152542372881,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.016949152542372881,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.012711864406779662,\n",
       " 0.016949152542372881]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_desc.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
